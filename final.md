# 🤖 AI/ML 최종 암기 노트 (Final Cheat Sheet)

---

### Part 1. 머신러닝 공통 기초

1.  **머신러닝 정의 (Tom Mitchell)**
    - **경험(E)**을 통해 **과제(T)**에 대한 **성능(P)**이 향상되는 것.

2.  **과적합 (Overfitting) & 해결책**
    - **정의**: 훈련 데이터에만 과도하게 최적화된 상태.
    - **해결책 4가지**:
        1.  더 많은 데이터 확보
        2.  더 단순한 모델 사용
        3.  **정규화 (Regularization)**
        4.  조기 중단 (Early Stopping)

3.  **데이터 분할의 역할**
    - **훈련 (Train)**: 모델 파라미터(가중치) 학습.
    - **검증 (Validation)**: 하이퍼파라미터 튜닝 및 과적합 확인.
    - **테스트 (Test)**: **모든 과정이 끝난 후 최종 성능 평가용 (절대 훈련에 사용 금지!)**.

4.  **교차 검증 (Cross-Validation)**
    - 데이터를 여러 번 쪼개서 모델을 평가하여, 평가 결과의 신뢰도를 높이는 방법.

5.  **판별 모델 vs 생성 모델**
    - **판별 모델**: 정답 맞히기(분류)에 집중. `p(y|x)`
    - **생성 모델**: 데이터가 어떻게 생겼는지(분포) 학습. `p(x,y)`

---

### Part 2. 핵심 지도 학습 모델

1.  **선형 회귀 (Linear Regression)**
    - **핵심**: 데이터에 가장 잘 맞는 '직선' 찾기.
    - **정규화**: 과적합 방지를 위해 가중치에 페널티 부여.
        - **Lasso (L1)**: 일부 가중치를 **완전히 0**으로 만듦 (**특성 선택** 효과).
        - **Ridge (L2)**: 가중치를 **0에 가깝게** 만듦 (전반적인 복잡도 감소).

2.  **의사결정 트리 (Decision Tree) & 랜덤 포레스트 (Random Forest)**
    - **의사결정 트리**: '스무고개'처럼 질문을 통해 데이터를 분할.
        - **분할 기준**: **정보 이득(Information Gain)**이 가장 큰 질문을 선택.
        - **단점**: 과적합에 매우 취약.
    - **랜덤 포레스트**: 과적합을 막기 위한 **'집단 지성'**.
        - **핵심 원리**: **배깅(Bagging)**. 데이터를 무작위로 샘플링하여 **여러 개의 약한 트리**를 만들고, 그 결과를 **투표(Voting)**해서 최종 결정을 내림.

---

### Part 3. 딥러닝 (CNN)

1.  **신경망의 핵심 개념**
    - **활성화 함수 (e.g., ReLU)**: 모델에 **비선형성**을 부여하여 복잡한 패턴을 학습하게 함. (이게 없으면 그냥 선형 모델임)
    - **역전파 (Backpropagation)**: 오차를 뒤로 전파하며 가중치를 효율적으로 업데이트하는 알고리즘.
    - **기울기 소실 (Vanishing Gradient)**: 깊은 네트워크에서 기울기가 사라져 학습이 안 되는 문제.

2.  **CNN (합성곱 신경망) - 이미지 처리 전문가**
    - **Convolution Layer**: 필터(커널)로 이미지를 훑으며 **특징(선, 질감 등)을 추출**.
    - **Pooling Layer**: 이미지 크기를 줄여(**다운샘플링**) 계산량을 줄이고, 위치 변화에 좀 더 강한 모델을 만듦.

---

### Part 4. 생성 모델 (Generative Models)

-   **공통 목표**: 훈련 데이터와 비슷한 **'가짜' 데이터를 새로 만들어내는 것**.

1.  **VAE (변분 오토인코더)**
    - **특징**: 안정적으로 훈련되지만, 결과물이 다소 흐릿할 수 있음.
    - **핵심**: 입력을 하나의 점이 아닌 **'확률 분포(평균, 분산)'**로 인코딩.

2.  **GAN (생성적 적대 신경망)**
    - **특징**: 결과물이 매우 선명하고 현실적이지만, 훈련이 불안정함.
    - **핵심**: **생성자(위조지폐범)**와 **판별자(경찰)**가 서로 경쟁하며 학습.

3.  **Diffusion Models (확산 모델)**
    - **특징**: 매우 높은 품질의 결과물, 안정적인 훈련. 하지만 생성 속도가 느림.
    - **핵심**: 이미지에 노이즈를 점진적으로 추가했다가, 그 **역과정(노이즈 제거)**을 학습.