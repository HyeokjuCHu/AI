# ECE30008 Intro to AI - Generative Models 요약

## 1. Generative AI 개요

### Generative AI의 응용 분야
- AI 검색
- 문서 요약
- 이미지 인페인팅
- 텍스트 생성
- 텍스트-이미지 생성
- 텍스트-비디오 생성
- 음악 생성
- 음성 생성
- 이미지 스타일 변환
- 가상 의류 착용
- 기타 다양한 창작 작업

### Generative Modeling의 목표
- **훈련 데이터가 주어졌을 때, 동일한 분포에서 새로운 샘플을 생성**
- **목표**:
  1. 데이터 분포 \( p_{data}(x) \)를 근사하는 모델 \( p_{model}(x) \) 학습
  2. \( p_{model}(x) \)에서 새로운 x 샘플링

## 2. Autoencoder

### 기본 개념
- **고차원 입력 신호를 저차원 잠재 표현으로 매핑한 후, 다시 원본 신호로 복원하는 모델**
- 정보 보존을 보장하면서 압축된 표현 학습

### Encoder의 역할
- 입력을 다른 표현으로 변환
- 압축된 표현 찾기
- 특징 추출
- 잠재 공간 발견

### Autoencoder 유형

#### 1. Basic Autoencoder
- 손실 함수: \( E(w) = \frac{1}{2} \sum_{n=1}^{N} \|y(x_n, w) - x_n\|^2 \)

#### 2. Sparse Autoencoder
- 손실 함수: \( \tilde{E}(w) = E(w) + \lambda \sum_{k=1}^{K} |z_k| \)
- 희소성 제약을 통한 더 효율적인 표현 학습

#### 3. Denoising Autoencoder (Vincent et al., 2008)
- **노이즈가 추가된 입력에서 깨끗한 이미지 복원 훈련**
- 손실 함수: \( E(w) = \sum_{n=1}^{N} \|y(\tilde{x}_n, w) - x_n\|^2 \)

#### 4. Masked Autoencoder (He et al., 2021)
- **입력 패치의 80%를 마스킹하고 복원 훈련**
- 자기지도학습의 효과적인 방법

### Deep Autoencoder
- **비선형 레이어(신경망) 포함으로 더 복잡한 표현 학습 가능**
- 여러 은닉층을 통한 계층적 특징 학습

## 3. Variational Autoencoder (VAE)

### 핵심 아이디어
- **Kingma and Welling (2013)이 제안한 생성 모델**
- 손실 함수를 통해 잠재 표현에 **사전 정의된 분포를 강제**
- 훈련 후 **새로운 샘플 생성 가능**

### 기본 Autoencoder vs VAE

#### 기본 Autoencoder
- 이미지를 잠재 공간의 **고정된 벡터**로 인코딩

#### VAE
- 이미지를 잠재 공간의 **분포에서 샘플링된 벡터**로 인코딩
- **확률적 인코더**: \( q_\phi(z|x) \)
- **확률적 디코더**: \( p_\theta(x|z) \)

### VAE 구조
- **인코더**: 평균(μ)과 표준편차(σ) 출력
- **샘플링**: \( z = \mu + \sigma \odot \epsilon \), \( \epsilon \sim \mathcal{N}(0,I) \)
- **디코더**: 샘플링된 z에서 이미지 재구성

### VAE의 장점
- **연속적인 잠재 공간** 형성
- 의미적으로 유사한 영역에서 샘플링 가능
- 잠재 공간 보간을 통한 새로운 샘플 생성

## 4. Generative Adversarial Network (GAN)

### 기본 개념
- **Goodfellow et al. (2014)이 제안**
- **생성자(Generator)**와 **판별자(Discriminator)**의 적대적 훈련
- 매우 현실적인 가짜 이미지 생성 가능

### GAN 구조
- **생성자(G)**: 잠재 공간에서 이미지 생성
- **판별자(D)**: 실제/가짜 이미지 구별
- **적대적 학습**: 생성자는 판별자를 속이려 하고, 판별자는 정확히 구별하려 함

### 훈련 과정
- **공동 훈련**: 생성자와 판별자를 동시에 훈련
- **목적 함수**:
$$\min_{\theta_g} \max_{\theta_d} \left[ \mathbb{E}_{x \sim \hat{p}} \log D_{\theta_d}(x) + \mathbb{E}_{z \sim p(z)} \log(1 - D_{\theta_d} \circ G_{\theta_g}(z)) \right]$$

### GAN의 네트워크 구조
- **판별자**: 표준 CNN (이미지 → 스칼라 확률)
- **생성자**: 역 CNN (잠재 벡터 → 고해상도 이미지)

## 5. Cycle GAN

### 핵심 아이디어
- **두 도메인 간의 양방향 매핑 학습**
- 페어 데이터 없이도 도메인 변환 가능
- **순환 일관성(Cycle Consistency)** 보장

### 구조
- **두 개의 생성자**: \( G_x, G_y \)
- **두 개의 판별자**: \( D_x, D_y \)
- **순환 일관성 손실**: F는 G의 역함수가 되어야 함

### 응용 사례
- 사진 ↔ 모네 그림
- 얼룩말 ↔ 말
- 여름 ↔ 겨울 풍경
- 다양한 예술 스타일 변환

## 6. Diffusion Models

### 기본 개념
- **Ho et al. (2020)이 제안**
- **점진적으로 가우시안 노이즈를 추가**하여 데이터를 파괴
- **역과정을 학습**하여 노이즈에서 데이터 생성

### 작동 원리
1. **Forward Process**: 데이터에 점진적으로 노이즈 추가
2. **Reverse Process**: 노이즈에서 점진적으로 데이터 복원
3. **확률적 과정**: \( p_\theta(x_{t-1}|x_t) \), \( q(x_t|x_{t-1}) \)

### 특징
- **안정적인 훈련**
- **고품질 샘플 생성**
- **다양성과 품질의 균형**

## 7. 생성 모델 비교

### 각 모델의 특성

#### GAN
- **장점**: 빠른 샘플링, 고품질 샘플
- **단점**: 훈련 불안정성, 모드 붕괴

#### VAE
- **장점**: 안정적 훈련, 다양성 보장
- **단점**: 상대적으로 낮은 샘플 품질

#### Diffusion Models
- **장점**: 높은 품질, 모드 커버리지
- **단점**: 느린 샘플링 속도

### 선택 기준
- **품질 우선**: GAN 또는 Diffusion Models
- **안정성 우선**: VAE 또는 Diffusion Models
- **속도 우선**: GAN
- **다양성 우선**: VAE 또는 Diffusion Models

## 8. 실제 응용

### 현재 활용 분야
- **이미지 생성**: DALL-E, Midjourney, Stable Diffusion
- **텍스트 생성**: GPT 시리즈
- **음성 합성**: WaveNet, Tacotron
- **비디오 생성**: Sora, RunwayML
- **3D 모델링**: NeRF, 3D GAN

### 미래 전망
- **멀티모달 생성**: 텍스트, 이미지, 음성, 비디오 통합
- **개인화된 생성**: 사용자 맞춤형 콘텐츠
- **실시간 생성**: 빠른 추론 속도
- **제어 가능한 생성**: 세밀한 조건부 생성

생성 모델은 현재 AI 분야에서 가장 활발히 연구되고 있는 영역 중 하나로, 창작, 엔터테인먼트, 교육, 의료 등 다양한 분야에서 혁신적인 변화를 이끌고 있습니다.